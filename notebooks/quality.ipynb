{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aabb72a",
   "metadata": {},
   "source": [
    "# Data Quality Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb68ecc0",
   "metadata": {},
   "source": [
    "This section contains code used to ensure that all available data has been successfully downloaded. While missing values may still occur, this part includes checks for missing chunks of data. Several cells are dedicated to identifying these gaps, ultimately producing a CSV file with the corresponding match IDs that need to be re-downloaded.\n",
    "\n",
    "Once this file is created, return to the fill_data.py script, comment out any unnecessary parts, and run the script to fetch the missing data.\n",
    "\n",
    "After a successful download, proceed to the second part of this notebook to merge the newly retrieved data.\n",
    "\n",
    "**ðŸ”§ Integration of this functionality into fill_data.py is planned to reduce manual effort.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a02c9",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b11ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d596ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"20_21_final\", \"21_22_final\", \"22_23_final\", \"23_24_final\"]\n",
    "dfs = [\n",
    "    pd.read_csv(f\"..\\data\\extracted_data\\{names[0]}.csv\"),\n",
    "    pd.read_csv(f\"..\\data\\extracted_data\\{names[1]}.csv\"),\n",
    "    pd.read_csv(f\"..\\data\\extracted_data\\{names[2]}.csv\"),\n",
    "    pd.read_csv(f\"..\\data\\extracted_data\\{names[3]}.csv\")\n",
    "]\n",
    "\n",
    "os.makedirs(\"../data/match_ids\", exist_ok=True)\n",
    "\n",
    "# Helper to save problematic match_ids to file\n",
    "def save_ids_to_file(ids, chunk_name, df_name):\n",
    "    file_path = f\"../data/match_ids/e{chunk_name}_{df_name}.csv\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        for match_id in ids:\n",
    "            f.write(f\"{match_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7802135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 1 â€” Check goals (Exception 1)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row['goals_1']) or pd.isna(row['goals_2']):\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 1, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551cb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 2 â€” Check possession (Exception 2)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row.get('possession_1')) or pd.isna(row.get('possession_2')):\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 2, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98cd35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 3 â€” Check formations (Exception 3)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row.get('team_1_formation')) or pd.isna(row.get('team_2_formation')):\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 3, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd39549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 4 â€” Check ratings (Exception 4)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row.get('team_1_line_1')) or pd.isna(row.get('team_2_line_1')):\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 4, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abf09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 5 â€” Check standard bets (Exception 5)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        cols = ['bet_1', 'bet_x', 'bet_2']\n",
    "        if sum(1 for col in cols if not pd.isna(row.get(col)) and isinstance(row[col], (int, float))) < 3:\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 5, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18161713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 6 â€” Check double chance bets (Exception 6)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    for _, row in df.iterrows():\n",
    "        cols = ['bet_1x', 'bet_12', 'bet_x2']\n",
    "        if sum(1 for col in cols if not pd.isna(row.get(col)) and isinstance(row[col], (int, float))) < 3:\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 6, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df771dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 7 â€” Check over/under bets (Exception 7)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    over_cols = [col for col in df.columns if col.startswith('bet_above_')]\n",
    "    under_cols = [col for col in df.columns if col.startswith('bet_below_')]\n",
    "    for _, row in df.iterrows():\n",
    "        above_valid = sum(1 for col in over_cols if not pd.isna(row.get(col)) and isinstance(row[col], (int, float)))\n",
    "        below_valid = sum(1 for col in under_cols if not pd.isna(row.get(col)) and isinstance(row[col], (int, float)))\n",
    "        if above_valid < 2 or below_valid < 2:\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 7, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d502fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNK 8 â€” Check handicap bets (Exception 8)\n",
    "for df, name in zip(dfs, names):\n",
    "    ids = []\n",
    "    handicap_cols = [col for col in df.columns if col.startswith('bet_handicap')]\n",
    "    for _, row in df.iterrows():\n",
    "        valid_handicaps = sum(1 for col in handicap_cols if not pd.isna(row.get(col)) and isinstance(row[col], (int, float)))\n",
    "        if valid_handicaps < 2:\n",
    "            ids.append(row['match_id'])\n",
    "    save_ids_to_file(ids, 8, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd2cf6",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29745392",
   "metadata": {},
   "source": [
    "This script is designed to enrich the main DataFrame `file1` with additional data from a secondary DataFrame `file2` by merging them on the match_id column.\n",
    "\n",
    "To use it:\n",
    "\n",
    "-Set the `file1` and `file2` variables to the desired input CSV file paths.\n",
    "\n",
    "-Adjust the output path in to_csv() to specify where the merged result should be saved.\n",
    "\n",
    "This is helpful when you want to add new columns or features to your primary dataset from an auxiliary data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8de6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r'..\\\\data\\\\extracted_data\\\\'\n",
    "file1 = f\"{directory}20_21_final.csv\"\n",
    "file2 = f\"{directory}20_21_exceptions.csv\"\n",
    "\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "merged_df = pd.merge(df1, df2, on='match_id', how='inner')\n",
    "\n",
    "merged_df.to_csv(f'{directory}merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
